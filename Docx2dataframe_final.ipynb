{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial will teach you how to transform a docx into a pandas dataframe and then save it as a CSV file.\n",
    "\n",
    "Prerequisites:\n",
    "* you will need Python installed on your computer\n",
    "* make sure that your file is a .docx and not a .doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install the appropriate Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specific to extracting information from word documents\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "#other tools useful in extracting the information from our document\n",
    "import re\n",
    "\n",
    "#to read XML and JSON\n",
    "from lxml import etree\n",
    "import json\n",
    "\n",
    "#to use dataframes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anatomy of a .docx file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is a docx file? Well, it is in fact an archive of xml files!\n",
    "Let's look at it.\n",
    "\n",
    "- Rename the file extension from .docx to .zip \n",
    "- Unzip the newly renamed file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file = \"burmese/burmese_selection\"\n",
    "#file = \"turkish/turkish_sample\"\n",
    "file = \"india/india_sample\"\n",
    "\n",
    "docxFileName = file+\".docx\"\n",
    "docxZip = zipfile.ZipFile(docxFileName)\n",
    "documentXML = docxZip.read('word/document.xml')\n",
    "stylesXML = docxZip.read('word/styles.xml')\n",
    "et = etree.XML(documentXML)\n",
    "ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to see what are the XML files hidden in your docx file you can use: `namelist()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docxZip.namelist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Title\n",
    "#ReferenceOld\n",
    "#ReferenceNew\n",
    "#Item date\n",
    "#Content description\n",
    "#Physical description\n",
    "#Creator\n",
    "#Language\n",
    "\n",
    "\n",
    "p = './w:r//w:t'\n",
    "ReferenceOld_xpath = './w:r[w:rPr[w:rStyle[@w:val=\"ReferenceOld\"]]]/w:t'\n",
    "ReferenceNew_xpath = './w:r[w:rPr[w:rStyle[@w:val=\"ReferenceNew\"]]]/w:t'\n",
    "PhysicalDescription_xpath = './w:r[w:rPr[w:rStyle[@w:val=\"PhysicalDescription\"]]][w:t]/w:t'\n",
    "ContentDescription_xpath = './w:pPr[w:pStyle[@w:val=\"ContentDescription\"]]/following-sibling::w:r/w:t'\n",
    "title_xpath = './w:pPr[w:pStyle[@w:val=\"Title\"]]/following-sibling::w:r/w:t'\n",
    "date_xpath = './w:r[w:rPr[w:rStyle[@w:val=\"ItemDate\"]]][w:t]/w:t'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ReferenceOld</th>\n",
       "      <th>ReferenceNew</th>\n",
       "      <th>Title</th>\n",
       "      <th>PhysicalDescription</th>\n",
       "      <th>ContentDescription</th>\n",
       "      <th>Item date</th>\n",
       "      <th>Language</th>\n",
       "      <th>Creator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mss. Eur. G. 1 .</td>\n",
       "      <td>[“ Rec d from Exam rs  Office\" 5 Oct. 1814.]\\...</td>\n",
       "      <td>50 x 30 cm, pp. 264.</td>\n",
       "      <td>There is no general title, but the manuscript ...</td>\n",
       "      <td>1914 and 1919.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Mss. Eur. D. 2</td>\n",
       "      <td>A Decree of the Holy Congregation Generall for...</td>\n",
       "      <td>30 x 18.5 cm, ' Foll . 3.</td>\n",
       "      <td>The watermarks are (a) Arms, Quarterly: 1st an...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>MSS. Eur. G. 2 .</td>\n",
       "      <td>Peticion of ye East India Company.</td>\n",
       "      <td>44 x 32' cm. One sheet, framed and hung in the...</td>\n",
       "      <td>This document is reproduced (actual size) in R...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>MSS.Eur . D.3 .</td>\n",
       "      <td>[Purchased 14 July 1916.]\\n[ Batavia's , Statu...</td>\n",
       "      <td>33 x '21 cm. pp., vi, 200</td>\n",
       "      <td>This volume is lettered \" Batasia's  Statut  B...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>MSS Eur F.1</td>\n",
       "      <td>[JOSIAH WEBBE?]</td>\n",
       "      <td>39 x 25 cm. pp. 126.</td>\n",
       "      <td>Verbael ,  uijt  afgesonden en aengekomen brie...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ReferenceOld       ReferenceNew  \\\n",
       "1             1  Mss. Eur. G. 1 .    \n",
       "2            2      Mss. Eur. D. 2   \n",
       "3            3    MSS. Eur. G. 2 .   \n",
       "4             4    MSS.Eur . D.3 .   \n",
       "5             5       MSS Eur F.1    \n",
       "\n",
       "                                                Title  \\\n",
       "1    [“ Rec d from Exam rs  Office\" 5 Oct. 1814.]\\...   \n",
       "2   A Decree of the Holy Congregation Generall for...   \n",
       "3                  Peticion of ye East India Company.   \n",
       "4   [Purchased 14 July 1916.]\\n[ Batavia's , Statu...   \n",
       "5                                     [JOSIAH WEBBE?]   \n",
       "\n",
       "                                  PhysicalDescription  \\\n",
       "1                                50 x 30 cm, pp. 264.   \n",
       "2                           30 x 18.5 cm, ' Foll . 3.   \n",
       "3   44 x 32' cm. One sheet, framed and hung in the...   \n",
       "4                           33 x '21 cm. pp., vi, 200   \n",
       "5                                39 x 25 cm. pp. 126.   \n",
       "\n",
       "                                   ContentDescription       Item date  \\\n",
       "1   There is no general title, but the manuscript ...  1914 and 1919.   \n",
       "2   The watermarks are (a) Arms, Quarterly: 1st an...                   \n",
       "3   This document is reproduced (actual size) in R...                   \n",
       "4   This volume is lettered \" Batasia's  Statut  B...                   \n",
       "5   Verbael ,  uijt  afgesonden en aengekomen brie...                   \n",
       "\n",
       "    Language  Creator  \n",
       "1        NaN      NaN  \n",
       "2        NaN      NaN  \n",
       "3        NaN      NaN  \n",
       "4        NaN      NaN  \n",
       "5        NaN      NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame()\n",
    "\n",
    "ReferenceOld_dic = {}\n",
    "ReferenceNew_dic = {}\n",
    "title_dic = {}\n",
    "ContentDescription_dic = {}\n",
    "PhysicalDescription_dic = {}\n",
    "date_dic = {}\n",
    "\n",
    "ReferenceOld = float('NaN')\n",
    "ReferenceNew = float('NaN')\n",
    "title = ''\n",
    "PhysicalDescription = ''\n",
    "ContentDescription = ''\n",
    "date = ''\n",
    "\n",
    "def populate_series(key, value, dictionary, mode):\n",
    "    if key not in dictionary:\n",
    "        dictionary[key] = value\n",
    "    if mode=='content': \n",
    "        if value not in dictionary[key]:\n",
    "            dictionary[key]+=\"\\n\"+value\n",
    "            value = ''\n",
    "    return dictionary, value\n",
    "    \n",
    "\n",
    "def get_info(para, xpath, field):\n",
    "    if para.xpath(xpath, namespaces=ns):\n",
    "        text = para.xpath(xpath, namespaces=ns)\n",
    "        field = \" \".join([t.text.strip() for t in text]).strip('\\n')\n",
    "    return field\n",
    "\n",
    "\n",
    "\n",
    "for i, para in enumerate(et.xpath('//w:p', namespaces=ns)):\n",
    "    \n",
    "    ##TODO: here we could add some contraints in case there is just old or new refernce (or we add it to the guidelines)\n",
    "    \n",
    "    ###extract info from word\n",
    "    \n",
    "    ReferenceOld = get_info(para, ReferenceOld_xpath, ReferenceOld)\n",
    "    ReferenceNew = get_info(para, ReferenceNew_xpath, ReferenceNew)\n",
    "    title = get_info(para, title_xpath, title)\n",
    "    PhysicalDescription = get_info(para, PhysicalDescription_xpath, PhysicalDescription)\n",
    "    ContentDescription = get_info(para, ContentDescription_xpath, ContentDescription)\n",
    "    date = get_info(para, date_xpath, date)\n",
    "           \n",
    "    ###create searies\n",
    "   \n",
    "    ReferenceOld_dic, ReferenceOld = populate_series(ReferenceOld, ReferenceOld, ReferenceOld_dic, \"ref\")\n",
    "    ReferenceNew_dic, ReferenceNew = populate_series(ReferenceOld, ReferenceNew, ReferenceNew_dic, \"ref\")\n",
    "    title_dic, title = populate_series(ReferenceOld, title, title_dic, \"content\")\n",
    "    date_dic, date = populate_series(ReferenceOld, date, date_dic, \"content\")\n",
    "    ContentDescription_dic, ContentDescription = populate_series(ReferenceOld, ContentDescription, ContentDescription_dic, \"content\")\n",
    "    PhysicalDescription_dic, PhysicalDescription = populate_series(ReferenceOld, PhysicalDescription, PhysicalDescription_dic, \"content\")\n",
    "\n",
    "            \n",
    "\n",
    "table = pd.DataFrame.from_dict({'ReferenceOld':pd.Series(ReferenceOld_dic),'ReferenceNew':pd.Series(ReferenceNew_dic),'Title':pd.Series(title_dic), 'PhysicalDescription':pd.Series(PhysicalDescription_dic), 'ContentDescription':pd.Series(ContentDescription_dic), 'Item date':pd.Series(date_dic)}\n",
    ")\n",
    "\n",
    "table = table.applymap(lambda x: x.strip('\\n') if type(x)==str else x)\n",
    "\n",
    "header_list = ['ReferenceOld','ReferenceNew', 'Title', 'PhysicalDescription','ContentDescription', 'Item date','Language','Creator']\n",
    "table = table.reindex(columns = header_list) \n",
    "table = table.dropna(how='all', subset=['ReferenceOld', 'ReferenceNew'])\n",
    "\n",
    "table.to_csv(file+\".csv\", encoding='utf-8-sig') \n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ReferenceNew_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, para in enumerate(et.xpath('//w:p', namespaces=ns)):\n",
    "    \n",
    "    \n",
    "    check = para.xpath(ReferenceOld_xpath, namespaces=ns)\n",
    "    if check:\n",
    "        text = para.xpath(ReferenceOld_xpath, namespaces=ns)\n",
    "        ReferenceOld = \" \".join([t.text.strip() for t in text]).strip('\\n')\n",
    "        print(ReferenceOld)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the initial position of each record\n",
    "\n",
    "cat_idx_pos = []\n",
    "\n",
    "for i, para in enumerate(et.xpath('//w:p', namespaces=ns)):\n",
    "    if para.xpath(ReferenceOld_xpath, namespaces=ns):\n",
    "        #print(i,para)\n",
    "        cat_idx_pos.append(i)\n",
    "print(cat_idx_pos)\n",
    "#print(etree.tostring(cats[0], pretty_print=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create ranges \n",
    "\n",
    "records = []\n",
    "for i,cat_id in enumerate(cat_idx_pos):\n",
    "    if cat_id != cat_idx_pos[-1]:\n",
    "        print\n",
    "        idx = range(cat_id, cat_idx_pos[i+1])\n",
    "        records.append([x for x in idx])\n",
    "print(records)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a catalogue including the relevant paras\n",
    "record = []\n",
    "catalogue_record_list = []\n",
    "\n",
    "for x in records:\n",
    "        for ix in x:\n",
    "            catalogue_record = etree.Element(\"record\")\n",
    "            for i, para in enumerate(et.xpath('//w:p', namespaces=ns)):\n",
    "                if i==ix:\n",
    "                    catalogue_record.append(copy.deepcopy(para))\n",
    "        catalogue_record_list.append(catalogue_record)\n",
    "        \n",
    "    \n",
    "          \n",
    "        #print(etree.tostring(catalogue_record, pretty_print=True))\n",
    "        \n",
    "len(catalogue_record_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "table_turkish = pd.DataFrame()\n",
    "table = pd.DataFrame()\n",
    "\n",
    "catalogue_record_list = catalogue_record_list[0]\n",
    "for cat_rec in catalogue_record_list:\n",
    "    for i, para in enumerate(cat_rec.xpath('./w:p', namespaces=ns)):\n",
    "\n",
    "        check = para.xpath(ReferenceOld_xpath, namespaces=ns)\n",
    "        if check:\n",
    "            ReferenceOld = para.xpath(ReferenceOld_xpath, namespaces=ns)[0].text.strip()\n",
    "        else:\n",
    "            ReferenceOld = ''\n",
    "\n",
    "        if para.xpath(title_xpath, namespaces=ns):\n",
    "            title = para.xpath(title_xpath, namespaces=ns)[0].text.strip()\n",
    "        else: \n",
    "            title = ''\n",
    "\n",
    "        if para.xpath(PhysicalDescription_xpath, namespaces=ns):\n",
    "            text = para.xpath(PhysicalDescription_xpath, namespaces=ns)\n",
    "            PhysicalDescription = \" \".join([t.text.strip() for t in text]).strip(' \\n')\n",
    "        else: \n",
    "            PhysicalDescription = ''\n",
    "\n",
    "            \n",
    "        if para.xpath(ContentDescription_xpath, namespaces=ns):\n",
    "            text = para.xpath(ContentDescription_xpath, namespaces=ns)\n",
    "            description = \" \".join([t.text.strip() for t in text]).strip(' \\n')\n",
    "            pilcrow = \"\"\"\n",
    "                \"\"\"\n",
    "            description = re.sub(r\"[\\r\\n]+\", pilcrow, description)\n",
    "        else:\n",
    "            description = ''\n",
    "\n",
    "        if para.xpath(date_xpath, namespaces=ns):\n",
    "            date = para.xpath(date_xpath, namespaces=ns)[0].text.strip()\n",
    "        else: \n",
    "            date = ''\n",
    "\n",
    "        table = table.append({'ReferenceOld':ReferenceOld, 'title': title, 'PhysicalDescription': PhysicalDescription, 'description': description, 'date': date}, ignore_index=True)\n",
    "        table.to_csv('test.csv', encoding=\"utf-8\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#approccio diverso\n",
    "\n",
    "\n",
    "catalogue_record_list = catalogue_record_list[0]\n",
    "for cat_rec in catalogue_record_list:\n",
    "    for i, para in enumerate(cat_rec.xpath('./w:p', namespaces=ns)):\n",
    "        catalogue = {}\n",
    "        \n",
    "        check = para.xpath(ReferenceOld_xpath, namespaces=ns)\n",
    "        if check:\n",
    "            ReferenceOld = para.xpath(ReferenceOld_xpath, namespaces=ns)[0].text.strip()\n",
    "        else:\n",
    "            ReferenceOld = ''\n",
    "\n",
    "        if para.xpath(title_xpath, namespaces=ns):\n",
    "            title = para.xpath(title_xpath, namespaces=ns)[0].text.strip()\n",
    "        else: \n",
    "            title = ''\n",
    "\n",
    "        if para.xpath(PhysicalDescription_xpath, namespaces=ns):\n",
    "            text = para.xpath(PhysicalDescription_xpath, namespaces=ns)\n",
    "            PhysicalDescription = \" \".join([t.text.strip() for t in text]).strip(' \\n')\n",
    "        else: \n",
    "            PhysicalDescription = ''\n",
    "\n",
    "            \n",
    "        if para.xpath(ContentDescription_xpath, namespaces=ns):\n",
    "            text = para.xpath(ContentDescription_xpath, namespaces=ns)\n",
    "            description = \" \".join([t.text.strip() for t in text]).strip(' \\n')\n",
    "            pilcrow = \"\"\"\n",
    "                \"\"\"\n",
    "            description = re.sub(r\"[\\r\\n]+\", pilcrow, description)\n",
    "        else:\n",
    "            description = ''\n",
    "\n",
    "        if para.xpath(date_xpath, namespaces=ns):\n",
    "            date = para.xpath(date_xpath, namespaces=ns)[0].text.strip()\n",
    "        else: \n",
    "            date = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in catalogue_record_list[0].xpath('w:p/w:r/w:t', namespaces=ns):\n",
    "    print(a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue_record_list[0].xpath('w:p/w:r', namespaces=ns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "et.xpath('//w:p', namespaces=ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
