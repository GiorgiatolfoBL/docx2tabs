{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Docx2dataframe_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiorgiatolfoBL/docx2tabs/blob/main/Docx2dataframe_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQKPuvSH3h8r"
      },
      "source": [
        "This tutorial will teach you how to transform a docx into a pandas dataframe and then save it as a CSV file.\n",
        "\n",
        "Prerequisites:\n",
        "* you will need Python installed on your computer\n",
        "* make sure that your file is a .docx and not a .doc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3nPBfv43h8u"
      },
      "source": [
        "## Install the appropriate Python packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEBxlgKa3h8u"
      },
      "source": [
        "#specific to extracting information from word documents\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "#other tools useful in extracting the information from our document\n",
        "import re\n",
        "\n",
        "#to read XML and JSON\n",
        "from lxml import etree\n",
        "import json\n",
        "\n",
        "#to use dataframes\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyvC30GWF04m"
      },
      "source": [
        "## Import the file\n",
        "* On the left side of colab, hover over the \"folder\" icon.\n",
        "* Click on the import icon and select your file.\n",
        "* Make sure your file is saved in the sample_data folder (if not, just drag and drop it inside it)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcWSNMiq3h8v"
      },
      "source": [
        "## Anatomy of a .docx file"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ai4KN5N_3h8v"
      },
      "source": [
        "What is a docx file? Well, it is in fact an archive of xml files!\n",
        "Let's look at it.\n",
        "\n",
        "In your local machine:\n",
        "- Rename the file extension from .docx to .zip \n",
        "- Unzip the newly renamed file\n",
        "\n",
        "Ok now we are ready.\n",
        "In the next cell look at \n",
        "\n",
        "```\n",
        "file = \"sample_data/india_sample\"\n",
        "```\n",
        "\n",
        "Make sure that the file you have uploaded is in the \"sample_data\" folder and that the name matches the one in the variable file (without extension). If not, amend it or reupload the file with the correct filename.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjQ-GD2z3h8v"
      },
      "source": [
        "file = \"sample_data/india_sample\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxapH_iVJKB3"
      },
      "source": [
        "Now let's load the file. The following bit of code will upload the file in the jupyter notebook and load the `document.xml` file inside your docx file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mnc7fi8rJJGP"
      },
      "source": [
        "docxFileName = file+\".docx\"\n",
        "docxZip = zipfile.ZipFile(docxFileName)\n",
        "documentXML = docxZip.read('word/document.xml')\n",
        "stylesXML = docxZip.read('word/styles.xml')\n",
        "et = etree.XML(documentXML)\n",
        "ns = {'w': 'http://schemas.openxmlformats.org/wordprocessingml/2006/main'}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llkTGPkw3h8v"
      },
      "source": [
        "If you want to see what are the XML files hidden in your docx file you can use: `namelist()`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IetsZewH3h8v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3484d5ab-d61a-4718-e668-b101ae6058ba"
      },
      "source": [
        "docxZip.namelist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['[Content_Types].xml',\n",
              " '_rels/.rels',\n",
              " 'word/_rels/document.xml.rels',\n",
              " 'word/document.xml',\n",
              " 'word/footer1.xml',\n",
              " 'word/footnotes.xml',\n",
              " 'word/endnotes.xml',\n",
              " 'word/footer2.xml',\n",
              " 'word/theme/theme1.xml',\n",
              " 'word/settings.xml',\n",
              " 'word/numbering.xml',\n",
              " 'word/styles.xml',\n",
              " 'word/webSettings.xml',\n",
              " 'docProps/core.xml',\n",
              " 'docProps/app.xml',\n",
              " 'customXml/itemProps1.xml',\n",
              " 'customXml/item1.xml',\n",
              " 'customXml/_rels/item1.xml.rels',\n",
              " 'word/fontTable.xml']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RNbF2pVtJxk9"
      },
      "source": [
        "## What is XPATH?\n",
        "For the purpose of this workshop we won't go into the details of xpath, but for more information you can read:\n",
        "https://www.w3schools.com/xml/xml_xpath.asp\n",
        "\n",
        "Suffice to say, in an xml, xpath tells the script where to find the information we are looking after."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IuIPAES3h8v"
      },
      "source": [
        "#Xpaths based on the paragraph/character styles defined in our word file.\n",
        "#Please note that styles should have the same name as those defined at the beginning of this tutorial.\n",
        "\n",
        "#paragrah unit\n",
        "p = './w:r//w:t'\n",
        "\n",
        "#charachter styles\n",
        "ReferenceOld_xpath = './w:r[w:rPr[w:rStyle[@w:val=\"ReferenceOld\"]]]/w:t'\n",
        "ReferenceNew_xpath = './w:r[w:rPr[w:rStyle[@w:val=\"ReferenceNew\"]]]/w:t'\n",
        "PhysicalDescription_xpath = './w:r[w:rPr[w:rStyle[@w:val=\"PhysicalDescription\"]]][w:t]/w:t'\n",
        "date_xpath = './w:r[w:rPr[w:rStyle[@w:val=\"ItemDate\"]]][w:t]/w:t'\n",
        "\n",
        "#paragraph styles\n",
        "ContentDescription_xpath = './w:pPr[w:pStyle[@w:val=\"ContentDescription\"]]/following-sibling::w:r/w:t'\n",
        "title_xpath = './w:pPr[w:pStyle[@w:val=\"Title\"]]/following-sibling::w:r/w:t'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwqyWYCSLvCX"
      },
      "source": [
        "Now we upload the document and let the script export the information in a pandas dataframe (tabular data)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9qlM0Bv3h8v",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "5f6e3fa0-ca65-4a33-e100-ca001b967108"
      },
      "source": [
        "table = pd.DataFrame()\n",
        "\n",
        "#initialisation\n",
        "\n",
        "ReferenceOld_dic = {}\n",
        "ReferenceNew_dic = {}\n",
        "title_dic = {}\n",
        "ContentDescription_dic = {}\n",
        "PhysicalDescription_dic = {}\n",
        "date_dic = {}\n",
        "\n",
        "ReferenceOld = float('NaN')\n",
        "ReferenceNew = float('NaN')\n",
        "title = ''\n",
        "PhysicalDescription = ''\n",
        "ContentDescription = ''\n",
        "date = ''\n",
        "\n",
        "#functions\n",
        "\n",
        "def get_info(para, xpath, field):\n",
        "    if para.xpath(xpath, namespaces=ns):\n",
        "        text = para.xpath(xpath, namespaces=ns)\n",
        "        field = \" \".join([t.text.strip() for t in text]).strip('\\n')\n",
        "    return field\n",
        "  \n",
        "\n",
        "def populate_series(key, value, dictionary, mode):\n",
        "    if key not in dictionary:\n",
        "        dictionary[key] = value\n",
        "    if mode=='content': \n",
        "        if value not in dictionary[key]:\n",
        "            dictionary[key]+=\"\\n\"+value\n",
        "            value = ''\n",
        "    return dictionary, value\n",
        "    \n",
        "\n",
        "for i, para in enumerate(et.xpath('//w:p', namespaces=ns)):\n",
        "      \n",
        "    ###extract info from word\n",
        "    \n",
        "    ReferenceOld = get_info(para, ReferenceOld_xpath, ReferenceOld)\n",
        "    ReferenceNew = get_info(para, ReferenceNew_xpath, ReferenceNew)\n",
        "    title = get_info(para, title_xpath, title)\n",
        "    PhysicalDescription = get_info(para, PhysicalDescription_xpath, PhysicalDescription)\n",
        "    ContentDescription = get_info(para, ContentDescription_xpath, ContentDescription)\n",
        "    date = get_info(para, date_xpath, date)\n",
        "           \n",
        "    ###create series\n",
        "   \n",
        "    ReferenceOld_dic, ReferenceOld = populate_series(ReferenceOld, ReferenceOld, ReferenceOld_dic, \"ref\")\n",
        "    ReferenceNew_dic, ReferenceNew = populate_series(ReferenceOld, ReferenceNew, ReferenceNew_dic, \"ref\")\n",
        "    title_dic, title = populate_series(ReferenceOld, title, title_dic, \"content\")\n",
        "    date_dic, date = populate_series(ReferenceOld, date, date_dic, \"content\")\n",
        "    ContentDescription_dic, ContentDescription = populate_series(ReferenceOld, ContentDescription, ContentDescription_dic, \"content\")\n",
        "    PhysicalDescription_dic, PhysicalDescription = populate_series(ReferenceOld, PhysicalDescription, PhysicalDescription_dic, \"content\")\n",
        "\n",
        "            \n",
        "\n",
        "table = pd.DataFrame.from_dict({'ReferenceOld':pd.Series(ReferenceOld_dic),'ReferenceNew':pd.Series(ReferenceNew_dic),'Title':pd.Series(title_dic), 'PhysicalDescription':pd.Series(PhysicalDescription_dic), 'ContentDescription':pd.Series(ContentDescription_dic), 'Item date':pd.Series(date_dic)}\n",
        ")\n",
        "\n",
        "table = table.applymap(lambda x: x.strip('\\n') if type(x)==str else x)\n",
        "\n",
        "#add Language and Creator columns\n",
        "header_list = ['ReferenceOld','ReferenceNew', 'Title', 'PhysicalDescription','ContentDescription', 'Item date','Language','Creator']\n",
        "table = table.reindex(columns = header_list) \n",
        "\n",
        "#remove rows without any ReferenceOld and ReferenceNew\n",
        "table = table.dropna(how='all', subset=['ReferenceOld', 'ReferenceNew'])\n",
        "\n",
        "#save the file as a .csv\n",
        "table.to_csv(file+\".csv\", encoding='utf-8-sig') \n",
        "\n",
        "#print the table \n",
        "table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ReferenceOld</th>\n",
              "      <th>ReferenceNew</th>\n",
              "      <th>Title</th>\n",
              "      <th>PhysicalDescription</th>\n",
              "      <th>ContentDescription</th>\n",
              "      <th>Item date</th>\n",
              "      <th>Language</th>\n",
              "      <th>Creator</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Mss. Eur. G. 1 .</td>\n",
              "      <td>[â€œ Rec d from Exam rs  Office\" 5 Oct. 1814.]\\...</td>\n",
              "      <td>50 x 30 cm, pp. 264.</td>\n",
              "      <td>There is no general title, but the manuscript ...</td>\n",
              "      <td>1914 and 1919.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Mss. Eur. D. 2</td>\n",
              "      <td>A Decree of the Holy Congregation Generall for...</td>\n",
              "      <td>30 x 18.5 cm, ' Foll . 3.</td>\n",
              "      <td>The watermarks are (a) Arms, Quarterly: 1st an...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>MSS. Eur. G. 2 .</td>\n",
              "      <td>Peticion of ye East India Company.</td>\n",
              "      <td>44 x 32' cm. One sheet, framed and hung in the...</td>\n",
              "      <td>This document is reproduced (actual size) in R...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>MSS.Eur . D.3 .</td>\n",
              "      <td>[Purchased 14 July 1916.]\\n[ Batavia's , Statu...</td>\n",
              "      <td>33 x '21 cm. pp., vi, 200</td>\n",
              "      <td>This volume is lettered \" Batasia's  Statut  B...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>MSS Eur F.1</td>\n",
              "      <td>[JOSIAH WEBBE?]</td>\n",
              "      <td>39 x 25 cm. pp. 126.</td>\n",
              "      <td>Verbael ,  uijt  afgesonden en aengekomen brie...</td>\n",
              "      <td></td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ReferenceOld       ReferenceNew  ... Language Creator\n",
              "1             1  Mss. Eur. G. 1 .   ...      NaN     NaN\n",
              "2            2      Mss. Eur. D. 2  ...      NaN     NaN\n",
              "3            3    MSS. Eur. G. 2 .  ...      NaN     NaN\n",
              "4             4    MSS.Eur . D.3 .  ...      NaN     NaN\n",
              "5             5       MSS Eur F.1   ...      NaN     NaN\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dnhC-n63h8w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvAlYLr3h8x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qDshdY03h8x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1put7CNl3h8x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDaUuOc53h8x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8CLOSX5a3h8x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OSHWggk3h8x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIoGi_Pd3h8y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}